{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d140991",
   "metadata": {},
   "source": [
    "# Topic Classification with BlazingText using Kaggle News Dataset\n",
    "Reference: https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/blazingtext_text_classification_dbpedia/blazingtext_text_classification_dbpedia.html#Training-the-BlazingText-model-for-supervised-text-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb4403",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ad6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::698264780541:role/service-role/AmazonSageMaker-ExecutionRole-20220330T145844\n",
      "urop1100f\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\n",
    "    role\n",
    ")  # the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = \"urop1100f\"\n",
    "print(bucket)\n",
    "prefix = \"topic_classification/blazingtext\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c33d1",
   "metadata": {},
   "source": [
    "## Load Dataset and Store in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6396a2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description        date  \n",
       "0  She left her husband. He killed their children...  2018-05-26  \n",
       "1                           Of course it has a song.  2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ...  2018-05-26  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "list_ = []\n",
    "with open(r\"News_Category_Dataset_v2.json\") as files:\n",
    "    for file in files:\n",
    "        list_.append(json.loads(file))\n",
    "df = pd.DataFrame(list_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4cba1",
   "metadata": {},
   "source": [
    "### Cluster similar categories: from 41 categories to 29 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the categories\n",
    "clusters = [['ARTS', 'ARTS & CULTURE', 'CULTURE & ARTS'],\n",
    " ['POLITICS', 'RELIGION'],\n",
    " ['PARENTING', 'PARENTS'],\n",
    " ['BLACK VOICES', 'LATINO VOICES', 'QUEER VOICES'],\n",
    " ['HEALTHY LIVING', 'HOME & LIVING'],\n",
    " ['STYLE', 'STYLE & BEAUTY'],\n",
    " ['COMEDY', 'ENTERTAINMENT'],\n",
    " ['WORLD NEWS', 'THE WORLDPOST', 'WORLDPOST'],\n",
    " ['COLLEGE', 'EDUCATION']]\n",
    "\n",
    "for ind, cluster in enumerate(clusters):\n",
    "    for c in cluster[1:]:\n",
    "        df['category'] = df['category'].str.replace(c, cluster[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d56688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       category\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...          CRIME\n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...  ENTERTAINMENT\n",
       "2  Hugh Grant Marries For The First Time At Age 5...  ENTERTAINMENT\n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...  ENTERTAINMENT\n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...  ENTERTAINMENT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group headline and description together\n",
    "df['text'] = df['headline'] + '. ' + df['short_description']\n",
    "df = df[['text', 'category']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc053be9",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ecccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162690, 2), (18077, 2), (20086, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_test_ratio = 0.9\n",
    "train_val_ratio = 0.9\n",
    "\n",
    "# train:test = 0.9:0.1\n",
    "train_val, test = np.split(df.sample(frac=1, random_state=1), [int(train_test_ratio * len(df))])\n",
    "train, val = np.split(train_val.sample(frac=1, random_state=1), [int(train_val_ratio * len(train_val))])\n",
    "\n",
    "# upload csv\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)\n",
    "\n",
    "train.shape, val.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587495cb",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a595fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "### preprocess the training data into space separated tokenized text format which can be consumed by BlazingText algorithm. \n",
    "### the class label(s) should be prefixed with __label__\n",
    "### it should be present in the same line along with the original sentence.\n",
    "\n",
    "def transform_instance(row):\n",
    "    cur_row = []\n",
    "    label = \"__label__\" + row[1]  # Prefix the index-ed label with __label__\n",
    "    cur_row.append(label)\n",
    "    cur_row.extend(nltk.word_tokenize(row[0].lower()))\n",
    "    return cur_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f95409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_file, output_file, keep=1):\n",
    "    all_rows = []\n",
    "    with open(input_file, \"r\") as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=\",\")\n",
    "        for row in csv_reader:\n",
    "            all_rows.append(row)\n",
    "    shuffle(all_rows)\n",
    "    all_rows = all_rows[: int(keep * len(all_rows))]\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    transformed_rows = pool.map(transform_instance, all_rows)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    with open(output_file, \"w\") as csvoutfile:\n",
    "        csv_writer = csv.writer(csvoutfile, delimiter=\" \", lineterminator=\"\\n\")\n",
    "        csv_writer.writerows(transformed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd99df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 322 ms, total: 3.48 s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Preparing the training dataset\n",
    "preprocess(\"train.csv\", \"kaggle.train\", keep=1)\n",
    "\n",
    "# Preparing the validation dataset\n",
    "preprocess(\"val.csv\", \"kaggle.validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547dd76",
   "metadata": {},
   "source": [
    "## Upload dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf7d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 396 ms, sys: 41.9 ms, total: 438 ms\n",
      "Wall time: 960 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + \"/train\"\n",
    "validation_channel = prefix + \"/validation\"\n",
    "\n",
    "sess.upload_data(path=\"kaggle.train\", bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path=\"kaggle.validation\", bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = \"s3://{}/{}\".format(bucket, train_channel)\n",
    "s3_validation_data = \"s3://{}/{}\".format(bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3752455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output location\n",
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b221a17",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc681322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:1 (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print(\"Using SageMaker BlazingText container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0782f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlazingText Model\n",
    "\n",
    "bt_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        \"mode\": \"supervised\",\n",
    "        \"min_count\": 2,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"vector_dim\": 64,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 4,\n",
    "        \"min_epochs\": 5\n",
    "        \"word_ngrams\": 2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc274c",
   "metadata": {},
   "source": [
    "### Link data channels to algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f251c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e686beb",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58a88540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-30 07:28:06 Starting - Starting the training job...\n",
      "2022-03-30 07:28:32 Starting - Preparing the instances for trainingProfilerReport-1648625286: InProgress\n",
      "......\n",
      "2022-03-30 07:29:32 Downloading - Downloading input data...\n",
      "2022-03-30 07:29:52 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 WARNING 139674839508800] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 WARNING 139674839508800] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 INFO 139674839508800] nvidia-smi took: 0.02520132064819336 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 INFO 139674839508800] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 INFO 139674839508800] Processing /opt/ml/input/data/train/kaggle.train . File size: 31.106579780578613 MB\u001b[0m\n",
      "\u001b[34m[03/30/2022 07:30:14 INFO 139674839508800] Processing /opt/ml/input/data/validation/kaggle.validation . File size: 3.4609127044677734 MB\u001b[0m\n",
      "\u001b[34mRead 5M words\u001b[0m\n",
      "\u001b[34mNumber of words:  57515\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/kaggle.validation\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0478  Progress: 4.47%  Million Words/sec: 18.70 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0452  Progress: 9.67%  Million Words/sec: 19.73 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0426  Progress: 14.85%  Million Words/sec: 20.03 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0400  Progress: 19.98%  Million Words/sec: 20.14 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0374  Progress: 25.16%  Million Words/sec: 20.24 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.607562\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0348  Progress: 30.47%  Million Words/sec: 18.45 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.628361\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.640172\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0318  Progress: 36.48%  Million Words/sec: 16.29 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.650572\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0289  Progress: 42.23%  Million Words/sec: 15.95 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.652429\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0261  Progress: 47.73%  Million Words/sec: 15.61 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.656366\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0232  Progress: 53.53%  Million Words/sec: 15.42 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 11\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.662606\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0203  Progress: 59.41%  Million Words/sec: 15.31 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 12\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.665429\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0178  Progress: 64.44%  Million Words/sec: 14.95 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 13\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.663869\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0147  Progress: 70.61%  Million Words/sec: 14.87 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 14\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.668697\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0118  Progress: 76.41%  Million Words/sec: 14.84 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 15\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.667954\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 16\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.668103\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 2 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0093  Progress: 81.42%  Million Words/sec: 14.53 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 17\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.669663\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0066  Progress: 86.78%  Million Words/sec: 14.43 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 18\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.670257\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0039  Progress: 92.21%  Million Words/sec: 14.24 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 19\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.670183\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\n",
      "2022-03-30 07:30:37 Uploading - Uploading generated training model\u001b[34m##### Alpha: 0.0009  Progress: 98.24%  Million Words/sec: 14.20 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 20\u001b[0m\n",
      "\u001b[34mUsing 8 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.670331\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 13.96 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 13.96\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 8.58\u001b[0m\n",
      "\u001b[34m#train_accuracy: 0.9101\u001b[0m\n",
      "\u001b[34mNumber of train examples: 121321\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.6703\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 18078\u001b[0m\n",
      "\n",
      "2022-03-30 07:30:53 Completed - Training job completed\n",
      "Training seconds: 82\n",
      "Billable seconds: 82\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd739a",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b621789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier = bt_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d6a92",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e114ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WOMEN\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.8411675095558167\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WOMEN\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.28858622908592224\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WORLDPOST\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.2353600412607193\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__IMPACT\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.2537541687488556\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__POLITICS\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.9926941990852356\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__SPORTS\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.5051364898681641\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__TRAVEL\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.402586966753006\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WELLNESS\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.48565739393234253\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WELLNESS\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.5202071070671082\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"label\": [\n",
      "      \"__label__WEDDINGS\"\n",
      "    ],\n",
      "    \"prob\": [\n",
      "      0.32708531618118286\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sentences = list(test.text)[:10]\n",
    "print(f\"test data: {len(sentences)}\")\n",
    "\n",
    "start_time = time.time()\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\": tokenized_sentences}\n",
    "\n",
    "response = text_classifier.predict(payload)\n",
    "\n",
    "predictions = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b9576e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WOMEN', 'ENTERTAINMENT', 'CRIME', 'GREEN', 'POLITICS', 'CRIME',\n",
       "       'FOOD & DRINK', 'POLITICS', 'WELLNESS', 'WEDDINGS'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.category.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5554db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(text_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f6bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
