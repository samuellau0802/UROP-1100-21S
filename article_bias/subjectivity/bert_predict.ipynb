{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer\n",
    "\n",
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\samue\\OneDrive - HKUST Connect\\year 2 spring\\UROP 1100\\UROP-1100-21S\\article_bias\\subjectivity\\model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        #self.labels = list(df['subjective'])\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def predict(model, data):\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    tokens = tokenizer(data, \n",
    "                            padding='max_length', max_length = 512, truncation=True,\n",
    "                            return_tensors=\"pt\")\n",
    "    \n",
    "    mask = tokens['attention_mask'].to(device)\n",
    "    input_id = tokens['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "    output = model(input_id, mask)\n",
    "    output = output[0].cpu().data.numpy()\n",
    "    output = softmax(output)\n",
    "        \n",
    "    return output[1]\n",
    "\n",
    "\n",
    "    \n",
    "result = predict(model, \"This is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>media_bias</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82596</td>\n",
       "      <td>Donald Trump blasts Bill Clinton as ’one of th...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Christopher Snyder</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160101000951/htt...</td>\n",
       "      <td>Donald Trump launched new attacks against Bil...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82600</td>\n",
       "      <td>Drop in oil prices rocks producer states, trig...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Brooke Singman</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>The plunge in oil prices has given a needed b...</td>\n",
       "      <td>right</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82605</td>\n",
       "      <td>Open carry comes to Texas: Why the Lone Star s...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>John R Lott</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>With about 900, 000 concealed handgun permit ...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82621</td>\n",
       "      <td>GOP field rips Obama’s move toward executive a...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Joseph Weber</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160104001421/htt...</td>\n",
       "      <td>Republican presidential candidates are attack...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82630</td>\n",
       "      <td>President Obama wants to disarm America</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Todd Starnes</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>President Obama is plotting with his attorney...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title publication  \\\n",
       "0  82596  Donald Trump blasts Bill Clinton as ’one of th...    Fox News   \n",
       "1  82600  Drop in oil prices rocks producer states, trig...    Fox News   \n",
       "2  82605  Open carry comes to Texas: Why the Lone Star s...    Fox News   \n",
       "3  82621  GOP field rips Obama’s move toward executive a...    Fox News   \n",
       "4  82630            President Obama wants to disarm America    Fox News   \n",
       "\n",
       "               author        date    year  month  \\\n",
       "0  Christopher Snyder  2015-12-30  2015.0   12.0   \n",
       "1      Brooke Singman  2016-01-01  2016.0    1.0   \n",
       "2         John R Lott  2015-12-30  2015.0   12.0   \n",
       "3        Joseph Weber  2016-01-03  2016.0    1.0   \n",
       "4        Todd Starnes  2016-01-04  2016.0    1.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://web.archive.org/web/20160101000951/htt...   \n",
       "1  https://web.archive.org/web/20160102032517/htt...   \n",
       "2  https://web.archive.org/web/20160102032517/htt...   \n",
       "3  https://web.archive.org/web/20160104001421/htt...   \n",
       "4  https://web.archive.org/web/20160105014544/htt...   \n",
       "\n",
       "                                             content media_bias     label  \n",
       "0   Donald Trump launched new attacks against Bil...      right  POLITICS  \n",
       "1   The plunge in oil prices has given a needed b...      right  BUSINESS  \n",
       "2   With about 900, 000 concealed handgun permit ...      right  POLITICS  \n",
       "3   Republican presidential candidates are attack...      right  POLITICS  \n",
       "4   President Obama is plotting with his attorney...      right  POLITICS  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\samue\\OneDrive - HKUST Connect\\year 2 spring\\UROP 1100\\UROP-1100-21S\\source_bias\\labelled_news_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>url</th>\n",
       "      <th>publication</th>\n",
       "      <th>media_bias</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump blasts Bill Clinton as ’one of th...</td>\n",
       "      <td>Donald Trump launched new attacks against Bil...</td>\n",
       "      <td>https://web.archive.org/web/20160101000951/htt...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Open carry comes to Texas: Why the Lone Star s...</td>\n",
       "      <td>With about 900, 000 concealed handgun permit ...</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GOP field rips Obama’s move toward executive a...</td>\n",
       "      <td>Republican presidential candidates are attack...</td>\n",
       "      <td>https://web.archive.org/web/20160104001421/htt...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>President Obama wants to disarm America</td>\n",
       "      <td>President Obama is plotting with his attorney...</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rancher family reports to prison, does not end...</td>\n",
       "      <td>As armed protesters occupied buildings on a f...</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Donald Trump blasts Bill Clinton as ’one of th...   \n",
       "2  Open carry comes to Texas: Why the Lone Star s...   \n",
       "3  GOP field rips Obama’s move toward executive a...   \n",
       "4            President Obama wants to disarm America   \n",
       "5  Rancher family reports to prison, does not end...   \n",
       "\n",
       "                                             content  \\\n",
       "0   Donald Trump launched new attacks against Bil...   \n",
       "2   With about 900, 000 concealed handgun permit ...   \n",
       "3   Republican presidential candidates are attack...   \n",
       "4   President Obama is plotting with his attorney...   \n",
       "5   As armed protesters occupied buildings on a f...   \n",
       "\n",
       "                                                 url publication media_bias  \\\n",
       "0  https://web.archive.org/web/20160101000951/htt...    Fox News      right   \n",
       "2  https://web.archive.org/web/20160102032517/htt...    Fox News      right   \n",
       "3  https://web.archive.org/web/20160104001421/htt...    Fox News      right   \n",
       "4  https://web.archive.org/web/20160105014544/htt...    Fox News      right   \n",
       "5  https://web.archive.org/web/20160105014544/htt...    Fox News      right   \n",
       "\n",
       "      label  \n",
       "0  POLITICS  \n",
       "2  POLITICS  \n",
       "3  POLITICS  \n",
       "4  POLITICS  \n",
       "5  POLITICS  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics = df[df['label'] == 'POLITICS']\n",
    "politics = politics[['title', 'content', 'url', 'publication', 'media_bias', 'label']]\n",
    "politics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics['subjectivity'] = politics.apply(lambda x: predict(model, x['content']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "politics.subjectivity.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00daf49d657fcaf7bdc5adbb3b43841207e448605290b2bd26bf112b8cca0df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('urop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
