{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_event</th>\n",
       "      <th>event</th>\n",
       "      <th>date_event</th>\n",
       "      <th>id_article</th>\n",
       "      <th>source</th>\n",
       "      <th>source_bias</th>\n",
       "      <th>url</th>\n",
       "      <th>ref</th>\n",
       "      <th>ref_url</th>\n",
       "      <th>article_bias</th>\n",
       "      <th>...</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001_Washington Post_1</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-kentucky-jo...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[10]: Johnson's wife, Rebecca, announced Thurs...</td>\n",
       "      <td>[11]: She spent the day at a funeral home arra...</td>\n",
       "      <td>[12]: \"Dan is gone but the story of his life i...</td>\n",
       "      <td>[13]: \"These high-tech lynchings based on lies...</td>\n",
       "      <td>[14]: I've been fighting behind my husband for...</td>\n",
       "      <td>[15]: Johnson's death shook his family, friend...</td>\n",
       "      <td>[16]: Gov.</td>\n",
       "      <td>[17]: Matt Bevin (R) wrote on Twitter: \"My hea...</td>\n",
       "      <td>[18]: [White House urges Roy Moore to concede,...</td>\n",
       "      <td>[19]: The tumult began Monday, when the Kentuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001_Washington Post_1</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-kentucky-jo...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[10]: Johnson's wife, Rebecca, announced Thurs...</td>\n",
       "      <td>[11]: She spent the day at a funeral home arra...</td>\n",
       "      <td>[12]: \"Dan is gone but the story of his life i...</td>\n",
       "      <td>[13]: \"These high-tech lynchings based on lies...</td>\n",
       "      <td>[14]: I've been fighting behind my husband for...</td>\n",
       "      <td>[15]: Johnson's death shook his family, friend...</td>\n",
       "      <td>[16]: Gov.</td>\n",
       "      <td>[17]: Matt Bevin (R) wrote on Twitter: \"My hea...</td>\n",
       "      <td>[18]: [White House urges Roy Moore to concede,...</td>\n",
       "      <td>[19]: The tumult began Monday, when the Kentuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001_Washington Post_1</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-kentucky-jo...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[10]: Johnson's wife, Rebecca, announced Thurs...</td>\n",
       "      <td>[11]: She spent the day at a funeral home arra...</td>\n",
       "      <td>[12]: \"Dan is gone but the story of his life i...</td>\n",
       "      <td>[13]: \"These high-tech lynchings based on lies...</td>\n",
       "      <td>[14]: I've been fighting behind my husband for...</td>\n",
       "      <td>[15]: Johnson's death shook his family, friend...</td>\n",
       "      <td>[16]: Gov.</td>\n",
       "      <td>[17]: Matt Bevin (R) wrote on Twitter: \"My hea...</td>\n",
       "      <td>[18]: [White House urges Roy Moore to concede,...</td>\n",
       "      <td>[19]: The tumult began Monday, when the Kentuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>001_Washington Post_1</td>\n",
       "      <td>left-center</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-kentucky-jo...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[10]: Johnson's wife, Rebecca, announced Thurs...</td>\n",
       "      <td>[11]: She spent the day at a funeral home arra...</td>\n",
       "      <td>[12]: \"Dan is gone but the story of his life i...</td>\n",
       "      <td>[13]: \"These high-tech lynchings based on lies...</td>\n",
       "      <td>[14]: I've been fighting behind my husband for...</td>\n",
       "      <td>[15]: Johnson's death shook his family, friend...</td>\n",
       "      <td>[16]: Gov.</td>\n",
       "      <td>[17]: Matt Bevin (R) wrote on Twitter: \"My hea...</td>\n",
       "      <td>[18]: [White House urges Roy Moore to concede,...</td>\n",
       "      <td>[19]: The tumult began Monday, when the Kentuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>002_CNN_1</td>\n",
       "      <td>left</td>\n",
       "      <td>http://www.cnn.com/2017/12/14/us/kentucky-stat...</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>https://www.reuters.com/article/us-kentucky-jo...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>[10]: The accuser, identified as Maranda Richm...</td>\n",
       "      <td>[11]: She said she was staying in a living are...</td>\n",
       "      <td>[12]: The center got its hands on police docum...</td>\n",
       "      <td>[13]: Johnson denied the allegations, a day af...</td>\n",
       "      <td>[14]: \"This allegation concerning this young g...</td>\n",
       "      <td>[15]: \"As a matter of fact, some of this I hea...</td>\n",
       "      <td>[16]: The same day Johnson held a news confere...</td>\n",
       "      <td>[17]: Johnson posted a message on his Facebook...</td>\n",
       "      <td>[18]: The post appears to have been deleted.</td>\n",
       "      <td>[19]: \"GOD and only GOD knows the truth, nothi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_event    event  date_event  id_article                 source  \\\n",
       "0         1  Johnson  2017-12-15         1.0  001_Washington Post_1   \n",
       "1         1  Johnson  2017-12-15         1.0  001_Washington Post_1   \n",
       "2         1  Johnson  2017-12-15         1.0  001_Washington Post_1   \n",
       "3         1  Johnson  2017-12-15         1.0  001_Washington Post_1   \n",
       "4         1  Johnson  2017-12-15         2.0              002_CNN_1   \n",
       "\n",
       "   source_bias                                                url      ref  \\\n",
       "0  left-center  https://www.washingtonpost.com/news/post-natio...  Reuters   \n",
       "1  left-center  https://www.washingtonpost.com/news/post-natio...  Reuters   \n",
       "2  left-center  https://www.washingtonpost.com/news/post-natio...  Reuters   \n",
       "3  left-center  https://www.washingtonpost.com/news/post-natio...  Reuters   \n",
       "4         left  http://www.cnn.com/2017/12/14/us/kentucky-stat...  Reuters   \n",
       "\n",
       "                                             ref_url  article_bias  ...  \\\n",
       "0  https://www.reuters.com/article/us-kentucky-jo...             1  ...   \n",
       "1  https://www.reuters.com/article/us-kentucky-jo...             3  ...   \n",
       "2  https://www.reuters.com/article/us-kentucky-jo...             3  ...   \n",
       "3  https://www.reuters.com/article/us-kentucky-jo...             3  ...   \n",
       "4  https://www.reuters.com/article/us-kentucky-jo...             4  ...   \n",
       "\n",
       "                                                 s10  \\\n",
       "0  [10]: Johnson's wife, Rebecca, announced Thurs...   \n",
       "1  [10]: Johnson's wife, Rebecca, announced Thurs...   \n",
       "2  [10]: Johnson's wife, Rebecca, announced Thurs...   \n",
       "3  [10]: Johnson's wife, Rebecca, announced Thurs...   \n",
       "4  [10]: The accuser, identified as Maranda Richm...   \n",
       "\n",
       "                                                 s11  \\\n",
       "0  [11]: She spent the day at a funeral home arra...   \n",
       "1  [11]: She spent the day at a funeral home arra...   \n",
       "2  [11]: She spent the day at a funeral home arra...   \n",
       "3  [11]: She spent the day at a funeral home arra...   \n",
       "4  [11]: She said she was staying in a living are...   \n",
       "\n",
       "                                                 s12  \\\n",
       "0  [12]: \"Dan is gone but the story of his life i...   \n",
       "1  [12]: \"Dan is gone but the story of his life i...   \n",
       "2  [12]: \"Dan is gone but the story of his life i...   \n",
       "3  [12]: \"Dan is gone but the story of his life i...   \n",
       "4  [12]: The center got its hands on police docum...   \n",
       "\n",
       "                                                 s13  \\\n",
       "0  [13]: \"These high-tech lynchings based on lies...   \n",
       "1  [13]: \"These high-tech lynchings based on lies...   \n",
       "2  [13]: \"These high-tech lynchings based on lies...   \n",
       "3  [13]: \"These high-tech lynchings based on lies...   \n",
       "4  [13]: Johnson denied the allegations, a day af...   \n",
       "\n",
       "                                                 s14  \\\n",
       "0  [14]: I've been fighting behind my husband for...   \n",
       "1  [14]: I've been fighting behind my husband for...   \n",
       "2  [14]: I've been fighting behind my husband for...   \n",
       "3  [14]: I've been fighting behind my husband for...   \n",
       "4  [14]: \"This allegation concerning this young g...   \n",
       "\n",
       "                                                 s15  \\\n",
       "0  [15]: Johnson's death shook his family, friend...   \n",
       "1  [15]: Johnson's death shook his family, friend...   \n",
       "2  [15]: Johnson's death shook his family, friend...   \n",
       "3  [15]: Johnson's death shook his family, friend...   \n",
       "4  [15]: \"As a matter of fact, some of this I hea...   \n",
       "\n",
       "                                                 s16  \\\n",
       "0                                         [16]: Gov.   \n",
       "1                                         [16]: Gov.   \n",
       "2                                         [16]: Gov.   \n",
       "3                                         [16]: Gov.   \n",
       "4  [16]: The same day Johnson held a news confere...   \n",
       "\n",
       "                                                 s17  \\\n",
       "0  [17]: Matt Bevin (R) wrote on Twitter: \"My hea...   \n",
       "1  [17]: Matt Bevin (R) wrote on Twitter: \"My hea...   \n",
       "2  [17]: Matt Bevin (R) wrote on Twitter: \"My hea...   \n",
       "3  [17]: Matt Bevin (R) wrote on Twitter: \"My hea...   \n",
       "4  [17]: Johnson posted a message on his Facebook...   \n",
       "\n",
       "                                                 s18  \\\n",
       "0  [18]: [White House urges Roy Moore to concede,...   \n",
       "1  [18]: [White House urges Roy Moore to concede,...   \n",
       "2  [18]: [White House urges Roy Moore to concede,...   \n",
       "3  [18]: [White House urges Roy Moore to concede,...   \n",
       "4       [18]: The post appears to have been deleted.   \n",
       "\n",
       "                                                 s19  \n",
       "0  [19]: The tumult began Monday, when the Kentuc...  \n",
       "1  [19]: The tumult began Monday, when the Kentuc...  \n",
       "2  [19]: The tumult began Monday, when the Kentuc...  \n",
       "3  [19]: The tumult began Monday, when the Kentuc...  \n",
       "4  [19]: \"GOD and only GOD knows the truth, nothi...  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/skymoonlight/biased-sents-annotation/master/Sora_LREC2020_biasedsentences.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_event', 'event', 'date_event', 'id_article', 'source',\n",
       "       'source_bias', 'url', 'ref', 'ref_url', 'article_bias', 't', '0', '1',\n",
       "       '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14',\n",
       "       '15', '16', '17', '18', '19', 'preknow', 'reftitle', 'reftext',\n",
       "       'doctitle', 'docbody', 's0', 's1', 's2', 's3', 's4', 's5', 's6', 's7',\n",
       "       's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17',\n",
       "       's18', 's19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
      "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_19032\\727445637.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A data analytics firm that worked with Donald ...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump showed an awkward sense of tim...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We've been promised by Google, Facebook, and o...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN) A Kentucky lawmaker accused of sexually ...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas Cowboys head coach Jason Garrett at the...</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>It's a game, ultimately, of restraint.</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Shut up.</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>This is the third time from the podium-always ...</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Former San Francisco 49ers quarterback Colin K...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>The practice was most famously done by former ...</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score\n",
       "0    A data analytics firm that worked with Donald ...   2.00\n",
       "1    President Trump showed an awkward sense of tim...   2.75\n",
       "2    We've been promised by Google, Facebook, and o...   2.25\n",
       "3    (CNN) A Kentucky lawmaker accused of sexually ...   2.25\n",
       "4    Dallas Cowboys head coach Jason Garrett at the...   1.60\n",
       "..                                                 ...    ...\n",
       "832             It's a game, ultimately, of restraint.   3.00\n",
       "833                                           Shut up.   3.00\n",
       "834  This is the third time from the podium-always ...   2.20\n",
       "835  Former San Francisco 49ers quarterback Colin K...   2.00\n",
       "836  The practice was most famously done by former ...   1.60\n",
       "\n",
       "[837 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, scores = [], []\n",
    "\n",
    "\n",
    "def format_df(ind, text, scores):\n",
    "    sentence_df = df[[str(ind), 's'+str(ind)]]\n",
    "    sentence_df = sentence_df.dropna()\n",
    "\n",
    "    for sentence in set(sentence_df['s'+str(ind)]):\n",
    "        score = sentence_df[sentence_df['s'+str(ind)] == sentence].mean().iloc[0]\n",
    "        text.append(sentence[sentence.index(\":\")+2:])\n",
    "        scores.append(score)\n",
    "\n",
    "    return text, scores\n",
    "\n",
    "for i in range(20):\n",
    "    text, scores = format_df(i, text, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A data analytics firm that worked with Donald ...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump showed an awkward sense of tim...</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We've been promised by Google, Facebook, and o...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(CNN) A Kentucky lawmaker accused of sexually ...</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas Cowboys head coach Jason Garrett at the...</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>It's a game, ultimately, of restraint.</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Shut up.</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>This is the third time from the podium-always ...</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Former San Francisco 49ers quarterback Colin K...</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>The practice was most famously done by former ...</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  score\n",
       "0    A data analytics firm that worked with Donald ...   2.00\n",
       "1    President Trump showed an awkward sense of tim...   2.75\n",
       "2    We've been promised by Google, Facebook, and o...   2.25\n",
       "3    (CNN) A Kentucky lawmaker accused of sexually ...   2.25\n",
       "4    Dallas Cowboys head coach Jason Garrett at the...   1.60\n",
       "..                                                 ...    ...\n",
       "832             It's a game, ultimately, of restraint.   3.00\n",
       "833                                           Shut up.   3.00\n",
       "834  This is the third time from the podium-always ...   2.20\n",
       "835  Former San Francisco 49ers quarterback Colin K...   2.00\n",
       "836  The practice was most famously done by former ...   1.60\n",
       "\n",
       "[837 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'text': text, 'score': scores})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATc0lEQVR4nO3df7BndX3f8edLIFGjCZi9IVvY9aqzmmKiK16R1mJIiA1CI5pkDExiwFpXG5nqJDMN0ozYzDhDG4GW2GLWwAhWERRRErB1pY5MZgq44BYXkLCQpe66sjfQsigMZJd3//iee/i63Lt7dvd+v+f+eD5mvnPP+Zxz7nl/5sze157POd9zUlVIkgTwvL4LkCQtHIaCJKllKEiSWoaCJKllKEiSWof3XcChWLFiRU1OTvZdhiQtKnfcccffV9XEbMsWdShMTk6ycePGvsuQpEUlyUNzLXP4SJLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSa2RhUKSVUm+keSeJHcn+WDT/pIkG5Lc3/w8qmlPkkuTbElyV5LjR1WbJGl2ozxT2A38UVUdB5wIfCDJccB5wM1VtQa4uZkHeCuwpvmsAy4bYW2SpFmMLBSqakdV3dlMPw7cCxwDnAFc2ax2JfD2ZvoM4KoauBU4MsnKUdUnSXqusXyjOckk8DrgNuDoqtrRLPoBcHQzfQzwvaHNtjVtO4baSLKOwZkEq1evHl3R0iGaPO/GXva79cLTe9mvloaRX2hO8iLgOuBDVbVreFkNXvt2QK9+q6r1VTVVVVMTE7M+ukOSdJBGGgpJjmAQCJ+tqi81zQ/PDAs1P3c27duBVUObH9u0SZLGZJR3HwW4HLi3qi4eWnQDcHYzfTbwlaH232/uQjoReGxomEmSNAajvKbwJuBdwHeSbGrazgcuBK5N8h7gIeCdzbKbgNOALcATwLtHWJskaRYjC4Wq+hsgcyw+ZZb1C/jAqOqRJO2f32iWJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSa5Sv47wiyc4km4farkmyqflsnXkjW5LJJE8OLfvkqOqSJM1tlK/j/DTwCeCqmYaq+p2Z6SQXAY8Nrf9AVa0dYT2SpP0Y5es4b0kyOduyJGHwbuZfHdX+JUkHrq9rCicBD1fV/UNtL0vy7STfTHJST3VJ0rI2yuGjfTkLuHpofgewuqoeSfJ64MtJXl1Vu/beMMk6YB3A6tWrx1KsJC0XYz9TSHI48JvANTNtVfVUVT3STN8BPAC8crbtq2p9VU1V1dTExMQ4SpakZaOP4aNfA75bVdtmGpJMJDmsmX45sAZ4sIfaJGlZG+UtqVcD/wt4VZJtSd7TLDqTHx86AngzcFdzi+oXgfdX1aOjqk2SNLtR3n101hzt58zSdh1w3ahqkSR109eFZvVg8rwbe9v31gtP723fkrrzMReSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqjfJ1nFck2Zlk81DbR5NsT7Kp+Zw2tOzDSbYkuS/Jr4+qLknS3Eb55rVPA58Artqr/ZKq+vhwQ5LjGLy7+dXAPwK+nuSVVbVnhPVpGejzbXPSYjSyM4WqugV4tOPqZwCfr6qnqurvgC3ACaOqTZI0uz6uKZyb5K5meOmopu0Y4HtD62xr2p4jybokG5NsnJ6eHnWtkrSsjDsULgNeAawFdgAXHegvqKr1VTVVVVMTExPzXJ4kLW9jDYWqeriq9lTVM8CneHaIaDuwamjVY5s2SdIYjfJC83MkWVlVO5rZdwAzdybdAHwuycUMLjSvAW4fZ20aLS/4SovDyEIhydXAycCKJNuAC4CTk6wFCtgKvA+gqu5Oci1wD7Ab+IB3HknS+I0sFKrqrFmaL9/H+h8DPjaqeiRJ++c3miVJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJLUNBktQyFCRJrZGFQpIrkuxMsnmo7c+SfDfJXUmuT3Jk0z6Z5Mkkm5rPJ0dVlyRpbp1CIckvHcTv/jRw6l5tG4BfrKrXAH8LfHho2QNVtbb5vP8g9idJOkRdzxT+a5Lbk/xBkp/pskFV3QI8ulfb16pqdzN7K3Bs91IlSaPWKRSq6iTgd4FVwB1JPpfkLYe4738JfHVo/mVJvp3km0lOmmujJOuSbEyycXp6+hBLkCQN63xNoaruB/4E+GPgl4FLm+sDv3mgO03y74DdwGebph3A6qp6HfCHwOeS/PQcdayvqqmqmpqYmDjQXUuS9qHrNYXXJLkEuBf4VeA3quofN9OXHMgOk5wD/Avgd6uqAKrqqap6pJm+A3gAeOWB/F5J0qE7vON6fw78JXB+VT0501hV30/yJ113luRU4N8Cv1xVTwy1TwCPVtWeJC8H1gAPdv29kqT50TUUTgeerKo9AEmeBzy/qp6oqs/MtkGSq4GTgRVJtgEXMLjb6CeBDUkAbm3uNHoz8KdJ/gF4Bnh/VT062++VJI1O11D4OvBrwA+b+RcCXwP+6VwbVNVZszRfPse61wHXdaxFkjQiXS80P7+qZgKBZvqFoylJktSXrqHwoyTHz8wkeT3w5D7WlyQtQl2Hjz4EfCHJ94EAPw/8zqiKkiT1o1MoVNW3kvwC8Kqm6b6q+ofRlSVJ6kPXMwWANwCTzTbHJ6GqrhpJVZKkXnQKhSSfAV4BbAL2NM0FGAqStIR0PVOYAo6b+QayJGlp6nr30WYGF5clSUtY1zOFFcA9SW4HnppprKq3jaQqSVIvuobCR0dZhCRpYeh6S+o3k7wUWFNVX0/yQuCw0ZYmSRq3ro/Ofi/wReAvmqZjgC+PqCZJUk+6Xmj+APAmYBe0L9z5uVEVJUnqR9dQeKqqnp6ZSXI4g+8pSJKWkK6h8M0k5wMvaN7N/AXgr0ZXliSpD11D4TxgGvgO8D7gJgbva5YkLSFd7z56BvhU85EkLVFd7z76uyQP7v3psN0VSXYm2TzU9pIkG5Lc3/w8qmlPkkuTbEly1/D7GyRJ49F1+GiKwVNS3wCcBFwK/LcO230aOHWvtvOAm6tqDXBzMw/wVmBN81kHXNaxNknSPOkUClX1yNBne1X9J+D0DtvdAjy6V/MZwJXN9JXA24far6qBW4Ejk6zsUp8kaX50fXT28FDO8xicORzIuxiGHV1VO5rpHwBHN9PHAN8bWm9b07ZjqI0k6xicSbB69eqDLEGSNJuuf9gvGpreDWwF3nmoO6+qSnJA33eoqvXAeoCpqSm/KyFJ86jr3Ue/Mo/7fDjJyqra0QwP7WzatwOrhtY7tmmTJI1J1+GjP9zX8qq6+AD2eQNwNnBh8/MrQ+3nJvk88EbgsaFhJknSGBzIm9fewOAPN8BvALcD9+9royRXAycDK5JsAy5gEAbXJnkP8BDPDkPdBJwGbAGeAN7duReSpHnRNRSOBY6vqscBknwUuLGqfm9fG1XVWXMsOmWWdYvBg/ckST3p+j2Fo4Gnh+af5tm7hiRJS0TXM4WrgNuTXN/Mv51nv2sgSVoiut599LEkX2XwbWaAd1fVt0dXliSpD12HjwBeCOyqqv8MbEvyshHVJEnqSdcH4l0A/DHw4abpCLo9+0iStIh0PVN4B/A24EcAVfV94MWjKkqS1I+uofB0c8toAST5qdGVJEnqS9dQuDbJXzB4cul7ga/jC3ckacnZ791HSQJcA/wCsAt4FfCRqtow4tokSWO231BonmR6U1X9EmAQSNIS1nX46M4kbxhpJZKk3nX9RvMbgd9LspXBHUhhcBLxmlEVJkkav32GQpLVVfV/gF8fUz2SpB7t70zhywyejvpQkuuq6rfGUJMkqSf7u6aQoemXj7IQSVL/9hcKNce0JGkJ2t/w0WuT7GJwxvCCZhqevdD80yOtTpI0VvsMhao6bL53mORVDL4MN+PlwEeAI4H3AtNN+/lVddN871+SNLeut6TOm6q6D1gLkOQwYDtwPYN3Ml9SVR8fd02SpIEDeZ/CKJwCPFBVD/VchySJ/kPhTODqoflzk9yV5IokR822QZJ1STYm2Tg9PT3bKpKkg9RbKCT5CQbvaPhC03QZ8AoGQ0s7gItm266q1lfVVFVNTUxMjKNUSVo2+jxTeCtwZ1U9DFBVD1fVnqp6hsFjuU/osTZJWpb6DIWzGBo6SrJyaNk7gM1jr0iSlrmx330E7Zvb3gK8b6j5PyZZy+BLclv3WiZJGoNeQqGqfgT87F5t7+qjFknSs3oJBUmjM3nejb3te+uFp/e2b82Pvm9JlSQtIIaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKllKEiSWoaCJKnV20t2kmwFHgf2ALurairJS4BrgEkGr+R8Z1X9375qlKTlpu8zhV+pqrVVNdXMnwfcXFVrgJubeUnSmPQdCns7A7iymb4SeHt/pUjS8tNnKBTwtSR3JFnXtB1dVTua6R8AR++9UZJ1STYm2Tg9PT2uWiVpWejtmgLwz6pqe5KfAzYk+e7wwqqqJLX3RlW1HlgPMDU19ZzlkqSD19uZQlVtb37uBK4HTgAeTrISoPm5s6/6JGk56iUUkvxUkhfPTAP/HNgM3ACc3ax2NvCVPuqTpOWqr+Gjo4Hrk8zU8Lmq+u9JvgVcm+Q9wEPAO3uqT5KWpV5CoaoeBF47S/sjwCnjr0iSBAvvllRJUo8MBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSq8+X7Cxbk+fd2HcJkjQrzxQkSS1DQZLUcvhI0rzpa2h064Wn97LfpcgzBUlSa+yhkGRVkm8kuSfJ3Uk+2LR/NMn2JJuaz2njrk2Slrs+ho92A39UVXcmeTFwR5INzbJLqurjPdQkSaKHUKiqHcCOZvrxJPcCx4y7DknSc/V6TSHJJPA64Lam6dwkdyW5IslRc2yzLsnGJBunp6fHVaokLQu9hUKSFwHXAR+qql3AZcArgLUMziQumm27qlpfVVNVNTUxMTGuciVpWeglFJIcwSAQPltVXwKoqoerak9VPQN8Cjihj9okaTnr4+6jAJcD91bVxUPtK4dWewewedy1SdJy18fdR28C3gV8J8mmpu184Kwka4ECtgLv66E2SVrW+rj76G+AzLLopnHXIkn6cX6jWZLUWtbPPvIR1pL04zxTkCS1DAVJUstQkCS1DAVJUstQkCS1lvXdR5KWBt/4Nn88U5AktQwFSVLLUJAktQwFSVLLUJAktQwFSVLLUJAktfyegiQdpD6ftDyq70h4piBJai24UEhyapL7kmxJcl7f9UjScrKgQiHJYcB/Ad4KHMfgvc3H9VuVJC0fCyoUgBOALVX1YFU9DXweOKPnmiRp2VhoF5qPAb43NL8NeOPwCknWAeua2R8mue8Q9rcC+PtD2H4hs2+L11Lun32bJ/kPh7T5S+dasNBCYb+qaj2wfj5+V5KNVTU1H79robFvi9dS7p99W/gW2vDRdmDV0PyxTZskaQwWWih8C1iT5GVJfgI4E7ih55okadlYUMNHVbU7ybnA/wAOA66oqrtHuMt5GYZaoOzb4rWU+2ffFrhUVd81SJIWiIU2fCRJ6pGhIElqLflQSHJFkp1JNs+xPEkubR6rcVeS48dd48Hq0LeTkzyWZFPz+ci4azxYSVYl+UaSe5LcneSDs6yzKI9dx74t5mP3/CS3J/nfTf/+/Szr/GSSa5pjd1uSyR5KPWAd+3ZOkumhY/ev+qj1oFXVkv4AbwaOBzbPsfw04KtAgBOB2/queR77djLw133XeZB9Wwkc30y/GPhb4LilcOw69m0xH7sAL2qmjwBuA07ca50/AD7ZTJ8JXNN33fPYt3OAT/Rd68F+lvyZQlXdAjy6j1XOAK6qgVuBI5OsHE91h6ZD3xatqtpRVXc2048D9zL4xvuwRXnsOvZt0WqOxw+b2SOaz953tJwBXNlMfxE4JUnGVOJB69i3RW3Jh0IHsz1aY8n8AwX+SXOq+9Ukr+67mIPRDC28jsH/yoYt+mO3j77BIj52SQ5LsgnYCWyoqjmPXVXtBh4DfnasRR6kDn0D+K1mSPOLSVbNsnzBMhSWtjuBl1bVa4E/B77cbzkHLsmLgOuAD1XVrr7rmU/76duiPnZVtaeq1jJ4KsEJSX6x55LmTYe+/RUwWVWvATbw7BnRomAoLOFHa1TVrplT3aq6CTgiyYqey+osyREM/mh+tqq+NMsqi/bY7a9vi/3Yzaiq/wd8Azh1r0XtsUtyOPAzwCNjLe4QzdW3qnqkqp5qZv8SeP2YSzskhsLgMRq/39zJciLwWFXt6Luo+ZDk52fGaZOcwOB4L4p/eE3dlwP3VtXFc6y2KI9dl74t8mM3keTIZvoFwFuA7+612g3A2c30bwP/s5qrtAtZl77tdV3rbQyuGS0aC+oxF6OQ5GoGd3KsSLINuIDBxSGq6pPATQzuYtkCPAG8u59KD1yHvv028K+T7AaeBM5cDP/wGm8C3gV8pxm/BTgfWA2L/th16dtiPnYrgSszeGnW84Brq+qvk/wpsLGqbmAQip9JsoXBzRJn9lfuAenSt3+T5G3AbgZ9O6e3ag+Cj7mQJLUcPpIktQwFSVLLUJAktQwFSVLLUJAktQwFSVLLUJAktf4/K6zVDt+8c1MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.score.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = list(df['score'])\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669 84 84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335/335 [01:03<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.583                | Train Accuracy:  0.000                 | Val Loss:  0.408                 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335/335 [01:04<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.311                | Train Accuracy:  0.000                 | Val Loss:  0.249                 | Val Accuracy:  0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335/335 [01:10<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.286                | Train Accuracy:  0.000                 | Val Loss:  0.258                 | Val Accuracy:  0.000\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "    \n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "                train_label = train_label.type(torch.LongTensor)\n",
    "                train_label = train_label.to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.type(torch.LongTensor)\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label)\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "               | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 3\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3769],\n",
      "        [1.8317]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.3728],\n",
      "        [2.5409]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.3404],\n",
      "        [0.7631]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[2.4742],\n",
      "        [1.5975]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\anaconda3\\envs\\urop\\lib\\site-packages\\torch\\nn\\modules\\loss.py:96: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8935],\n",
      "        [2.2618]], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([[1.6965],\n",
      "        [2.1093]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.9831],\n",
      "        [0.9347]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.4533],\n",
      "        [0.4974]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[1.9308],\n",
      "        [0.8924]], device='cuda:0')\n",
      "tensor([2, 1], device='cuda:0')\n",
      "tensor([[2.0495],\n",
      "        [2.0649]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.0298],\n",
      "        [1.7821]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.5617],\n",
      "        [1.4878]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.7267],\n",
      "        [1.9180]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.9202],\n",
      "        [1.4766]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.7659],\n",
      "        [1.2285]], device='cuda:0')\n",
      "tensor([1, 3], device='cuda:0')\n",
      "tensor([[1.8530],\n",
      "        [1.9803]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[1.9459],\n",
      "        [1.5127]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.0362],\n",
      "        [1.7822]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.2826],\n",
      "        [0.7697]], device='cuda:0')\n",
      "tensor([2, 1], device='cuda:0')\n",
      "tensor([[1.6133],\n",
      "        [1.3344]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.4105],\n",
      "        [2.1594]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.7564],\n",
      "        [1.6650]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[1.6754],\n",
      "        [1.8221]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.6285],\n",
      "        [1.3490]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[2.0623],\n",
      "        [1.2177]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.8870],\n",
      "        [2.1657]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[2.0174],\n",
      "        [1.7016]], device='cuda:0')\n",
      "tensor([3, 1], device='cuda:0')\n",
      "tensor([[1.5811],\n",
      "        [1.5512]], device='cuda:0')\n",
      "tensor([1, 1], device='cuda:0')\n",
      "tensor([[2.0703],\n",
      "        [1.3218]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.1257],\n",
      "        [1.9384]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.0064],\n",
      "        [1.6912]], device='cuda:0')\n",
      "tensor([2, 1], device='cuda:0')\n",
      "tensor([[1.2303],\n",
      "        [1.7094]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.4513],\n",
      "        [1.0548]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[2.2182],\n",
      "        [2.0520]], device='cuda:0')\n",
      "tensor([2, 1], device='cuda:0')\n",
      "tensor([[2.0989],\n",
      "        [2.4170]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.6327],\n",
      "        [1.4659]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.8632],\n",
      "        [1.8318]], device='cuda:0')\n",
      "tensor([3, 2], device='cuda:0')\n",
      "tensor([[1.9499],\n",
      "        [1.3762]], device='cuda:0')\n",
      "tensor([3, 1], device='cuda:0')\n",
      "tensor([[1.8329],\n",
      "        [2.2791]], device='cuda:0')\n",
      "tensor([2, 1], device='cuda:0')\n",
      "tensor([[1.5227],\n",
      "        [1.8412]], device='cuda:0')\n",
      "tensor([1, 2], device='cuda:0')\n",
      "tensor([[1.5918],\n",
      "        [1.8379]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "tensor([[1.4803],\n",
      "        [1.2704]], device='cuda:0')\n",
      "tensor([2, 2], device='cuda:0')\n",
      "Total mse: 21.512531280517578\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    criterion = nn.L1Loss()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "            test_label = test_label.type(torch.LongTensor)\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            print(output)\n",
    "            print(test_label)\n",
    "            \n",
    "            mse = criterion(output, test_label)\n",
    "            #acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += mse\n",
    "    \n",
    "    print(f'Total mse: {total_acc_test}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00daf49d657fcaf7bdc5adbb3b43841207e448605290b2bd26bf112b8cca0df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('urop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
