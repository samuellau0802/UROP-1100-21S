{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>media_bias</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82596</td>\n",
       "      <td>Donald Trump blasts Bill Clinton as ’one of th...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Christopher Snyder</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160101000951/htt...</td>\n",
       "      <td>Donald Trump launched new attacks against Bil...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82600</td>\n",
       "      <td>Drop in oil prices rocks producer states, trig...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Brooke Singman</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>The plunge in oil prices has given a needed b...</td>\n",
       "      <td>right</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82605</td>\n",
       "      <td>Open carry comes to Texas: Why the Lone Star s...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>John R Lott</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>With about 900, 000 concealed handgun permit ...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82621</td>\n",
       "      <td>GOP field rips Obama’s move toward executive a...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Joseph Weber</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160104001421/htt...</td>\n",
       "      <td>Republican presidential candidates are attack...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82630</td>\n",
       "      <td>President Obama wants to disarm America</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Todd Starnes</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>President Obama is plotting with his attorney...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title publication  \\\n",
       "0  82596  Donald Trump blasts Bill Clinton as ’one of th...    Fox News   \n",
       "1  82600  Drop in oil prices rocks producer states, trig...    Fox News   \n",
       "2  82605  Open carry comes to Texas: Why the Lone Star s...    Fox News   \n",
       "3  82621  GOP field rips Obama’s move toward executive a...    Fox News   \n",
       "4  82630            President Obama wants to disarm America    Fox News   \n",
       "\n",
       "               author        date    year  month  \\\n",
       "0  Christopher Snyder  2015-12-30  2015.0   12.0   \n",
       "1      Brooke Singman  2016-01-01  2016.0    1.0   \n",
       "2         John R Lott  2015-12-30  2015.0   12.0   \n",
       "3        Joseph Weber  2016-01-03  2016.0    1.0   \n",
       "4        Todd Starnes  2016-01-04  2016.0    1.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://web.archive.org/web/20160101000951/htt...   \n",
       "1  https://web.archive.org/web/20160102032517/htt...   \n",
       "2  https://web.archive.org/web/20160102032517/htt...   \n",
       "3  https://web.archive.org/web/20160104001421/htt...   \n",
       "4  https://web.archive.org/web/20160105014544/htt...   \n",
       "\n",
       "                                             content media_bias     label  \n",
       "0   Donald Trump launched new attacks against Bil...      right  POLITICS  \n",
       "1   The plunge in oil prices has given a needed b...      right  BUSINESS  \n",
       "2   With about 900, 000 concealed handgun permit ...      right  POLITICS  \n",
       "3   Republican presidential candidates are attack...      right  POLITICS  \n",
       "4   President Obama is plotting with his attorney...      right  POLITICS  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\samue\\OneDrive - HKUST Connect\\year 2 spring\\UROP 1100\\UROP-1100-21S\\source_bias\\labelled_news_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>media_bias</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82596</td>\n",
       "      <td>Donald Trump blasts Bill Clinton as ’one of th...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Christopher Snyder</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160101000951/htt...</td>\n",
       "      <td>Donald Trump launched new attacks against Bil...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82605</td>\n",
       "      <td>Open carry comes to Texas: Why the Lone Star s...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>John R Lott</td>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://web.archive.org/web/20160102032517/htt...</td>\n",
       "      <td>With about 900, 000 concealed handgun permit ...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82621</td>\n",
       "      <td>GOP field rips Obama’s move toward executive a...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Joseph Weber</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160104001421/htt...</td>\n",
       "      <td>Republican presidential candidates are attack...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82630</td>\n",
       "      <td>President Obama wants to disarm America</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Todd Starnes</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>President Obama is plotting with his attorney...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82631</td>\n",
       "      <td>Rancher family reports to prison, does not end...</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Hollie McKay</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://web.archive.org/web/20160105014544/htt...</td>\n",
       "      <td>As armed protesters occupied buildings on a f...</td>\n",
       "      <td>right</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title publication  \\\n",
       "0  82596  Donald Trump blasts Bill Clinton as ’one of th...    Fox News   \n",
       "2  82605  Open carry comes to Texas: Why the Lone Star s...    Fox News   \n",
       "3  82621  GOP field rips Obama’s move toward executive a...    Fox News   \n",
       "4  82630            President Obama wants to disarm America    Fox News   \n",
       "5  82631  Rancher family reports to prison, does not end...    Fox News   \n",
       "\n",
       "               author        date    year  month  \\\n",
       "0  Christopher Snyder  2015-12-30  2015.0   12.0   \n",
       "2         John R Lott  2015-12-30  2015.0   12.0   \n",
       "3        Joseph Weber  2016-01-03  2016.0    1.0   \n",
       "4        Todd Starnes  2016-01-04  2016.0    1.0   \n",
       "5        Hollie McKay  2016-01-04  2016.0    1.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://web.archive.org/web/20160101000951/htt...   \n",
       "2  https://web.archive.org/web/20160102032517/htt...   \n",
       "3  https://web.archive.org/web/20160104001421/htt...   \n",
       "4  https://web.archive.org/web/20160105014544/htt...   \n",
       "5  https://web.archive.org/web/20160105014544/htt...   \n",
       "\n",
       "                                             content media_bias     label  \n",
       "0   Donald Trump launched new attacks against Bil...      right  POLITICS  \n",
       "2   With about 900, 000 concealed handgun permit ...      right  POLITICS  \n",
       "3   Republican presidential candidates are attack...      right  POLITICS  \n",
       "4   President Obama is plotting with his attorney...      right  POLITICS  \n",
       "5   As armed protesters occupied buildings on a f...      right  POLITICS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics = df[df['label'] == \"POLITICS\"]\n",
    "politics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "politics.media_bias.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(politics[politics['media_bias'] == 'right']['title'] + ' ' + politics[politics['media_bias'] == 'right']['content']).to_csv(r'right.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(politics[politics['media_bias'] == 'center']['title'] + ' ' + politics[politics['media_bias'] == 'center']['content']).to_csv(r'center.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = (politics['media_bias'] == 'center') | (politics['media_bias'] == 'left-center')\n",
    "(politics[left]['title'] + ' ' + politics[left]['content']).to_csv(r'left.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a word2vec model using Keras\n",
    "[reference link](https://www.tensorflow.org/tutorials/text/word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=SEED,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      negative_sampling_candidates = tf.expand_dims(\n",
    "          negative_sampling_candidates, 1)\n",
    "\n",
    "      context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = r\"left.txt\"\n",
    "# Use the non empty lines to construct a tf.data.TextLineDataset object for the next step\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the text and remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "\n",
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 8192\n",
    "sequence_length = 10\n",
    "\n",
    "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
    "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
    "# same length.\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call TextVectorization.adapt on the text dataset to create vocabulary\n",
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'to', 'of', 'a', 'and', 'in', 'that', 'for', 'on', 'is', 'he', 'trump', 'said', 'with', 'as', 'was', 'his', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Save the created vocabulary for reference.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data in text_ds.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59044\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  83   13  132 3872   32    1  739    3    2  126] => ['donald', 'trump', 'may', 'pose', 'an', '[UNK]', 'threat', 'to', 'the', 'united']\n",
      "[  13    1 4687  194 1900    1  193    2 2840 7018] => ['trump', '[UNK]', 'dismiss', 'russia', 'scandal', '[UNK]', 'me', 'the', 'proof', '–']\n",
      "[  13    1 1136    1  654    7 2416    3  341  259] => ['trump', '[UNK]', 'firm', '[UNK]', 'millions', 'in', 'donations', 'to', 'family', 'members']\n",
      "[1271    1 4897    1 4177    3  255   78   59  306] => ['tom', '[UNK]', 'sends', '[UNK]', 'machine', 'to', 'help', 'white', 'house', 'press']\n",
      "[   2 2104  100    2    1 4333    2  218  317 7916] => ['the', 'resistance', 'now', 'the', '[UNK]', 'shock', 'the', 'world', 'again', 'jeremy']\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences[:5]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59044/59044 [03:31<00:00, 279.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (357234,)\n",
      "contexts.shape: (357234, 5)\n",
      "labels.shape: (357234, 5)\n"
     ]
    }
   ],
   "source": [
    "# sequences is now a list of int encoded sentences. \n",
    "# Just call the generate_training_data function defined earlier to generate training examples for the word2vec model. \n",
    "# To recap, the function iterates over each word from each sequence to collect positive and negative context words. \n",
    "# Length of target, contexts and labels should be the same, representing the total number of training examples.\n",
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)[:,:,0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# To perform efficient batching for the potentially large number of training examples, use the tf.data.Dataset API. \n",
    "# After this step, you would have a tf.data.Dataset object of (target_word, context_word), (label) elements to train your word2vec model\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ns = 4\n",
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=num_ns+1)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
    "    # context: (batch, context)\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    # target: (batch,)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    # word_emb: (batch, embed)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    # context_emb: (batch, context, embed)\n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    # dots: (batch, context)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the tf.keras.optimizers.Adam optimizer\n",
    "embedding_dim = 512\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a callback to log training statistics for Tensorboard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "348/348 [==============================] - 3s 7ms/step - loss: 1.4187 - accuracy: 0.4683\n",
      "Epoch 2/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.9917 - accuracy: 0.6618\n",
      "Epoch 3/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.7135 - accuracy: 0.7765\n",
      "Epoch 4/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.5308 - accuracy: 0.8444\n",
      "Epoch 5/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.4150 - accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.3390 - accuracy: 0.9071\n",
      "Epoch 7/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.2872 - accuracy: 0.9212\n",
      "Epoch 8/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.2508 - accuracy: 0.9297\n",
      "Epoch 9/20\n",
      "348/348 [==============================] - 4s 10ms/step - loss: 0.2246 - accuracy: 0.9351\n",
      "Epoch 10/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.2054 - accuracy: 0.9383\n",
      "Epoch 11/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.1911 - accuracy: 0.9402\n",
      "Epoch 12/20\n",
      "348/348 [==============================] - 3s 9ms/step - loss: 0.1803 - accuracy: 0.9412\n",
      "Epoch 13/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.1719 - accuracy: 0.9420\n",
      "Epoch 14/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.1654 - accuracy: 0.9424\n",
      "Epoch 15/20\n",
      "348/348 [==============================] - 4s 10ms/step - loss: 0.1603 - accuracy: 0.9426\n",
      "Epoch 16/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.1561 - accuracy: 0.9429\n",
      "Epoch 17/20\n",
      "348/348 [==============================] - 3s 8ms/step - loss: 0.1527 - accuracy: 0.9430\n",
      "Epoch 18/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.1499 - accuracy: 0.9430\n",
      "Epoch 19/20\n",
      "348/348 [==============================] - 3s 7ms/step - loss: 0.1476 - accuracy: 0.9431\n",
      "Epoch 20/20\n",
      "348/348 [==============================] - 2s 7ms/step - loss: 0.1456 - accuracy: 0.9431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ae41f9640>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the dataset for some number of epochs:\n",
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.index('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.86749576e-02, -6.12386204e-02,  2.70390630e-01,  1.90143242e-01,\n",
       "        2.26660237e-01,  2.24874511e-01,  2.98920274e-01, -1.43385231e-01,\n",
       "       -1.25935078e-02,  2.07506105e-01, -4.29424167e-01, -8.44037607e-02,\n",
       "        2.29998231e-01, -6.34588078e-02, -1.40479475e-01,  1.05438985e-01,\n",
       "        2.35229686e-01, -9.63032767e-02, -3.13956439e-01, -3.57617408e-01,\n",
       "        2.29396299e-01,  4.72083926e-01,  1.62651036e-02,  5.36824644e-01,\n",
       "        1.05337583e-01, -3.99604887e-01, -1.80477679e-01,  2.49578059e-01,\n",
       "        2.15667058e-02, -2.53508240e-01, -3.08201224e-01,  9.67082977e-02,\n",
       "       -1.22923948e-01, -1.19751386e-01, -2.88152307e-01,  1.64688125e-01,\n",
       "        1.92297086e-01, -3.21670741e-01,  8.94936919e-02,  2.66031742e-01,\n",
       "       -8.63884240e-02, -4.49477956e-02,  7.46417344e-02, -6.49946854e-02,\n",
       "       -2.42764968e-02,  2.13135570e-01,  2.17116490e-01, -2.39124238e-01,\n",
       "        6.21166267e-02,  6.19892925e-02, -1.44255579e-01, -1.78941675e-02,\n",
       "        5.65028861e-02,  2.11736590e-01, -1.93318412e-01, -1.29635155e-01,\n",
       "        1.36339548e-03, -1.75445661e-01,  3.04692149e-01, -7.56063238e-02,\n",
       "        1.96263731e-01, -1.71922799e-02,  1.53542295e-01,  2.81147450e-01,\n",
       "       -6.20372593e-02,  1.04592377e-02,  2.16627896e-01,  1.18215658e-01,\n",
       "       -3.48188281e-02,  9.47159678e-02, -3.37146789e-01, -7.61791915e-02,\n",
       "       -4.56831865e-02,  2.80196905e-01,  5.02502859e-01, -2.33069599e-01,\n",
       "        1.12473071e-01,  6.85743988e-02,  9.70615149e-02,  5.17698586e-01,\n",
       "       -7.09732845e-02,  2.00922251e-01, -5.17728217e-02, -9.78403166e-02,\n",
       "        2.19793081e-01, -3.10540617e-01,  3.68061811e-01, -1.81611240e-01,\n",
       "        2.77434379e-01, -3.15896034e-01,  2.21275508e-01, -1.12827025e-01,\n",
       "       -1.45221800e-01,  2.72346407e-01, -5.47374003e-02, -7.67768472e-02,\n",
       "       -2.01756045e-01, -7.24666938e-02,  4.74009961e-02, -1.27792761e-01,\n",
       "        1.07582666e-01, -1.66792825e-01,  1.57383114e-01,  3.11886728e-01,\n",
       "        2.21115351e-01, -6.40487745e-02,  1.24952853e-01,  1.35061055e-01,\n",
       "       -2.58154850e-02,  1.50228530e-01, -5.72937839e-02,  2.61334386e-02,\n",
       "       -1.38279237e-02,  1.24061473e-01,  2.13183224e-01, -1.02063650e-02,\n",
       "       -1.41628101e-01,  2.06345860e-02,  8.82025883e-02,  1.03534430e-01,\n",
       "        4.71634120e-02,  2.53024817e-01,  3.33024919e-01,  3.34740207e-02,\n",
       "       -4.93846759e-02,  3.41627300e-01,  3.78372371e-01,  5.31693697e-01,\n",
       "       -4.37810235e-02,  1.32885233e-01,  1.71740800e-01, -1.30024152e-02,\n",
       "       -3.34996641e-01,  1.15309156e-01,  1.54497787e-01, -1.26100332e-01,\n",
       "       -3.20216984e-01, -2.93696404e-01, -3.28213960e-01,  2.46238738e-01,\n",
       "       -4.12394047e-01, -5.91377243e-02,  2.29699090e-01,  2.64279451e-02,\n",
       "       -1.02996975e-01, -1.79907903e-01,  2.28713959e-01, -1.53455913e-01,\n",
       "       -3.37460972e-02, -2.65880346e-01,  3.51440787e-01,  2.32868135e-01,\n",
       "       -9.23866034e-02,  3.02782595e-01, -1.70833290e-01, -3.32423031e-01,\n",
       "       -1.80924967e-01, -1.39898777e-01, -2.29732111e-01, -3.89171205e-02,\n",
       "        9.69077051e-02, -7.98365921e-02,  2.66612738e-01, -1.77236244e-01,\n",
       "        1.77072421e-01,  7.51756877e-02, -2.49839365e-01,  7.42107034e-02,\n",
       "        7.60401934e-02,  3.45096499e-01,  2.95555979e-01, -3.15312356e-01,\n",
       "        2.49262556e-01, -7.16997907e-02,  5.93934879e-02,  1.29655832e-02,\n",
       "       -1.19953394e-01, -1.68037191e-01,  2.88067479e-02, -1.89438965e-02,\n",
       "        2.56670684e-01,  1.81133449e-01, -3.25827688e-01, -9.47734937e-02,\n",
       "        2.39813596e-01, -1.46069452e-01, -1.07792489e-01,  2.48105213e-01,\n",
       "        4.88941580e-01, -1.06980681e-01, -2.78723508e-01,  2.19823703e-01,\n",
       "       -2.48846918e-01,  4.77889031e-02,  2.34580621e-01, -3.19134831e-01,\n",
       "        1.38349801e-01, -4.02799696e-02,  2.44394690e-01, -3.93347800e-01,\n",
       "       -2.53299139e-02,  2.39075080e-01,  4.64900600e-04,  2.76062071e-01,\n",
       "        3.94237995e-01,  2.06694812e-01, -3.69659394e-01, -4.21999432e-02,\n",
       "        2.16919094e-01,  2.05334909e-02, -1.73440009e-01,  2.34305225e-02,\n",
       "        1.50573686e-01, -3.60648006e-01,  4.75744039e-01,  2.27530450e-01,\n",
       "       -4.79251631e-02, -1.19402431e-01,  2.89893031e-01,  1.29019096e-01,\n",
       "       -1.34455159e-01, -3.53287280e-01, -3.05116326e-01, -8.03116634e-02,\n",
       "        7.68121406e-02,  1.45695597e-01,  4.85187113e-01, -3.37944031e-01,\n",
       "       -2.72378981e-01, -2.22338349e-01,  2.76708305e-01, -3.56222838e-02,\n",
       "       -7.50345513e-02,  7.39391297e-02,  2.75240064e-01, -4.47963038e-03,\n",
       "        2.01345176e-01, -2.93045521e-01,  2.86088455e-02, -3.00508529e-01,\n",
       "        2.27455661e-01, -1.23844542e-01,  7.92733729e-02, -5.16046695e-02,\n",
       "       -3.69596928e-02, -1.99212909e-01,  2.93784171e-01, -5.00697307e-02,\n",
       "        1.25988528e-01, -4.75991890e-02,  9.60272178e-02,  1.25473648e-01,\n",
       "        3.32466245e-01, -1.44818705e-02,  7.86120445e-02, -2.41179019e-01,\n",
       "        6.98159486e-02, -4.80918884e-02,  1.50748789e-01, -1.90040395e-02,\n",
       "       -6.71254797e-03,  4.24843282e-01,  3.71632338e-01, -1.26430959e-01,\n",
       "       -2.22667634e-01, -2.27894764e-02,  2.55527467e-01, -4.21369851e-01,\n",
       "       -4.34753820e-02,  1.68210760e-01,  2.35984683e-01, -1.28555402e-01,\n",
       "       -1.52156800e-01, -1.81547806e-01,  1.38967961e-01, -2.05572128e-01,\n",
       "       -1.04380667e-01, -1.01232633e-01,  2.90243685e-01, -1.19472980e-01,\n",
       "       -7.62291923e-02,  9.24076065e-02,  1.87998369e-01, -1.68952242e-01,\n",
       "       -7.03722835e-02, -3.79608683e-02,  1.87951148e-01, -3.34076703e-01,\n",
       "       -6.94118217e-02, -5.27426451e-02,  1.89716250e-01, -1.66967914e-01,\n",
       "        2.97407895e-01,  2.78679430e-01,  3.52714270e-01,  1.49025321e-01,\n",
       "        9.67750773e-02, -6.45471811e-02, -1.32463485e-01, -5.20873368e-02,\n",
       "        5.60698733e-02, -8.17948729e-02, -7.72182941e-02,  8.55241567e-02,\n",
       "        2.43751723e-02,  2.31329083e-01, -3.45860459e-02, -8.75401273e-02,\n",
       "        2.84442872e-01, -1.15846090e-01,  2.85452306e-01, -6.55406043e-02,\n",
       "        2.06664726e-02, -1.28224999e-01,  2.46715263e-01, -1.83902115e-01,\n",
       "        1.18108436e-01,  1.91724151e-02, -8.53835642e-02,  3.30258943e-02,\n",
       "       -8.13618749e-02,  2.68270195e-01,  3.95181358e-01,  3.32654029e-01,\n",
       "        2.90466100e-01, -1.97700232e-01, -2.04330221e-01, -2.17702568e-01,\n",
       "       -1.28800198e-01, -1.25026211e-01, -9.83090997e-02, -1.14260390e-01,\n",
       "        1.85778797e-01,  1.25729010e-01,  1.10371001e-01, -2.30024293e-01,\n",
       "        2.33688340e-01, -1.51921853e-01,  2.58770585e-01,  3.99626195e-02,\n",
       "        3.04841369e-01, -7.36903921e-02, -7.62662441e-02, -1.14537053e-01,\n",
       "       -1.79204911e-01,  2.46000439e-01,  1.56853914e-01,  4.33174521e-01,\n",
       "       -1.41709030e-01, -4.14581783e-02, -3.23540658e-01,  7.28874505e-02,\n",
       "        2.74993360e-01, -4.55831140e-02,  2.30883271e-01, -8.80438462e-02,\n",
       "       -2.65871465e-01, -1.53186977e-01, -1.01095386e-01,  1.92785114e-01,\n",
       "        2.49352217e-01,  6.81086257e-02,  1.08541794e-01,  6.80933520e-02,\n",
       "        1.49155274e-01, -2.02144355e-01, -2.62566864e-01, -3.38260531e-01,\n",
       "       -1.71159178e-01,  1.98706627e-01,  1.96799293e-01, -2.07315490e-01,\n",
       "       -5.10194637e-02,  5.62677272e-02,  2.95106947e-01, -1.50697187e-01,\n",
       "        2.22491130e-01, -8.14060271e-02,  1.25009418e-02, -1.59561142e-01,\n",
       "        2.53138930e-01, -7.08574504e-02, -1.31588519e-01, -2.68071502e-01,\n",
       "        2.98148036e-01,  2.87461784e-02, -3.82548161e-02, -1.03593975e-01,\n",
       "       -7.32570365e-02, -2.21082330e-01, -1.50383860e-01,  6.64936751e-02,\n",
       "        4.00997162e-01,  6.23830259e-02,  3.13259624e-02,  1.09223448e-01,\n",
       "       -2.56942928e-01,  2.62347944e-02, -8.51636156e-02, -5.04766591e-02,\n",
       "        3.04347783e-01,  6.44886354e-03, -2.28536259e-02, -3.09641004e-01,\n",
       "       -3.46197873e-01,  3.11241839e-02, -1.70160756e-01,  1.05782516e-01,\n",
       "        1.86321035e-01, -2.54468888e-01, -1.91273719e-01, -1.30340084e-01,\n",
       "        2.39793912e-01,  8.87633115e-03, -1.88820347e-01, -3.03622305e-01,\n",
       "       -3.35167617e-01, -1.72578007e-01,  3.58238257e-02,  9.85956267e-02,\n",
       "        1.50611773e-01,  2.54027247e-01,  1.37704924e-01, -3.52853417e-01,\n",
       "        2.36686289e-01, -1.08588785e-01,  3.21582071e-02,  2.06897721e-01,\n",
       "        3.06634098e-01,  9.97650474e-02, -1.61128938e-01, -3.63602526e-02,\n",
       "        7.07746074e-02, -2.52988804e-02,  2.77389050e-01,  1.45042434e-01,\n",
       "       -2.00702786e-01,  1.44067526e-01,  2.25973338e-01, -6.57800257e-01,\n",
       "       -7.86120594e-02, -1.74228907e-01, -4.06225711e-01,  2.96994317e-02,\n",
       "       -3.91421497e-01,  1.26466185e-01, -4.15669829e-02,  4.66876291e-03,\n",
       "       -1.15568489e-01,  1.43774852e-01,  7.55968839e-02, -5.23692891e-02,\n",
       "        1.85884982e-01, -4.03268307e-01, -7.65922889e-02,  4.30804670e-01,\n",
       "       -6.38594553e-02, -5.76617718e-02,  4.80777472e-02, -1.66732110e-02,\n",
       "       -8.51136968e-02, -1.42753348e-01,  3.88448425e-02, -1.42471924e-01,\n",
       "        1.34495506e-02,  3.07137370e-02, -1.11371845e-01, -9.92971659e-02,\n",
       "       -1.70065865e-01, -9.72235948e-02,  1.20103797e-02, -2.44720742e-01,\n",
       "       -1.78136677e-02,  1.39394149e-01, -1.93258718e-01,  1.60329626e-03,\n",
       "       -1.30267158e-01,  6.96275756e-02, -6.02709763e-02,  1.13904126e-01,\n",
       "        3.84286731e-01,  3.00225377e-01,  3.33996892e-01, -3.69577855e-02,\n",
       "        1.43576220e-01,  2.06455752e-01, -1.60598248e-01,  4.68242951e-02,\n",
       "        1.57254174e-01, -2.12992609e-01,  3.87849696e-02,  1.94356874e-01,\n",
       "       -4.74574715e-02, -1.73771292e-01,  1.18238449e-01, -1.23365007e-01,\n",
       "        2.72001065e-02, -7.06661418e-02,  2.99057275e-01, -2.66113043e-01,\n",
       "        1.74148545e-01, -6.47781193e-02, -3.90173078e-01,  1.04688160e-01,\n",
       "       -8.83568004e-02,  2.34529138e-01,  1.21504225e-01,  1.33243158e-01,\n",
       "       -1.27741665e-01, -4.02433008e-01, -1.17093377e-01, -4.12301272e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save the vectors and metadata files\n",
    "out_v = io.open('left_vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('left_metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f00daf49d657fcaf7bdc5adbb3b43841207e448605290b2bd26bf112b8cca0df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('urop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
